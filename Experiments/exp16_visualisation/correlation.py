import matplotlib.pyplot as plt
import numpy as np
from scipy import stats

from api_extraction import get_segmented_flow_syscalls
from clustering import cluster_segmented_flow, SegmentedConvertor
from comparaison_classes import CachedLCS, CachedSW, CachedCustomLCS
from segmentation import get_segmentation

TIME_DELAY_ALLOWED = 10


def intra_cluster_quality_matrix(cluster):
	# Too heavy to compute
	LCS_engine = CachedLCS()
	n = len(cluster)
	matrix = np.zeros((n, n))
	if n == 0:
		return 0
	for i in range(n):
		for j in range(i):
			matrix[i][j] = LCS_engine.compute(cluster[:, 1], cluster[:, 1])
	# print(matrix)
	return np.sum(matrix) / (n * (n - 1) / 2)


def custom_dist(a, b):
	return a != b


def inter_cluster_similarity_matrix(cluster1, cluster2, random=True):
	similarity_engine = CachedCustomLCS(c_lib=True)
	m, n = len(cluster1), len(cluster2)
	if m == 0 or n == 0:
		return None
	if not random:
		matrix = np.zeros((m, n))
		for i in range(m):
			for j in range(n):
				matrix[i][j] = similarity_engine.compute(cluster1[i], cluster2[j])
		return np.max(matrix)
	else:
		i, j = np.random.randint(0, m), np.random.randint(0, n)
		sim = similarity_engine.compute(cluster1[i], cluster2[j])
		return sim


def inter_cluster_intention_matrix(cluster1, cluster2, random=False):
	similarity_engine = CachedSW(c_lib=True)
	m, n = len(cluster1), len(cluster2)
	if m == 0 or n == 0:
		return None
	if not random:
		matrix = np.zeros((m, n))
		for i in range(m):
			for j in range(n):
				matrix[i][j] = similarity_engine.compute(cluster1[i][:, 1], cluster2[j][:, 1])
		return np.mean(matrix)
	else:
		len1, len2 = 0, 0
		x, y = [], []
		while(len1 < 100 and len2 < 100):
			i, j = np.random.randint(0, m), np.random.randint(0, n)
			x, y = cluster1[i][:, 1], cluster2[j][:, 1]
			len1, len2 = len(x), len(y)
		sim = similarity_engine.compute(x, y)
		return sim


# return np.sum(matrix) / (n * m)


def get_malware_segmentation_cluster_sequence(path, malware_process_name):
	# Get the segmentation in flows
	segmentations, _ = get_segmentation(path=path, malware_process_name=malware_process_name)
	cluster_indexes, nb_class = cluster_segmented_flow(segmentations)
	call_dict = {k: np.empty((0, 4)) for k in range(nb_class)}
	call_dict2 = {k: [] for k in range(nb_class)}
	for i in range(len(segmentations)):
		segmentation = segmentations[i]
		cluster = cluster_indexes[i]
		syscalls = get_segmented_flow_syscalls(segmentation, malware_process_name, path=path,
		                                       time_delay_allowed=TIME_DELAY_ALLOWED)
		if syscalls.shape[0]:
			call_dict[cluster] = np.vstack((call_dict[cluster], syscalls))
			call_dict2[cluster].append(syscalls)
	for k, v in call_dict.items():
		print(f"Cluster {k} : {v.shape}")
		sorted_indexes = np.argsort(v[:, -1])
		call_dict[k] = v[sorted_indexes]
	return segmentations, cluster_indexes, nb_class, call_dict, call_dict2


def correlate(list_of_paths):
	segmentations_list, cluster_indexes_list, nb_classes_list, call_dict1_list, call_dict2_list = [], [], [], [], []
	X = []
	Y = []
	segmented_convertor = SegmentedConvertor()
	for path in list_of_paths:
		segmentations1, cluster_indexes1, nb_class1, call_dict_1, call_dict2_1 = get_malware_segmentation_cluster_sequence(
			path, "malware.exe")
		segmentations_list.append(segmentations1)
		cluster_indexes_list.append(cluster_indexes1)
		nb_classes_list.append(nb_class1)
		call_dict1_list.append(call_dict_1)
		call_dict2_list.append(call_dict2_1)
	for x in range(len(segmentations_list)):
		for y in range(x):
			segmentations1, cluster_indexes1, nb_class1, call_dict_1, call_dict2_1 = segmentations_list[x], \
			                                                                         cluster_indexes_list[x], \
			                                                                         nb_classes_list[x], \
			                                                                         call_dict1_list[x], \
			                                                                         call_dict2_list[x]
			segmentations2, cluster_indexes2, nb_class2, call_dict_2, call_dict2_2 = segmentations_list[y], \
			                                                                         cluster_indexes_list[y], \
			                                                                         nb_classes_list[y], \
			                                                                         call_dict1_list[y], \
			                                                                         call_dict2_list[y]
			for i in range(nb_class1):
				for j in range(nb_class2):
					intention = inter_cluster_intention_matrix(call_dict2_1[i], call_dict2_2[j])
					typegroups1 = segmented_convertor.segmented_to_typegroups(segmentations1)
					typegroups2 = segmented_convertor.segmented_to_typegroups(segmentations2)
					appearance = inter_cluster_similarity_matrix(
						np.array(typegroups1)[cluster_indexes1 == i],
						np.array(typegroups2)[cluster_indexes2 == j])
					if intention is None or appearance is None:
						continue
					X.append(appearance)
					Y.append(intention)
	segmented_convertor.print_dict()
	plt.figure()
	plt.xlabel("Cluster similarity")
	plt.ylabel("API Call Sequence similarity")
	h = plt.hist2d(X, Y, bins=[25, 25], range=[[0, 1], [0, 1]])
	plt.colorbar(h[3])
	plt.plot([0, 1], [0, 1], ls="--", c=".3")
	plt.savefig('./figure.png')
	pear = stats.pearsonr(X, Y)
	spear = stats.spearmanr(X, Y)
	print(pear, spear)


# TODO: do matrix on this to answer research question 1

if __name__ == "__main__":
	np.random.seed(1)
	correlate(["trickbot1_4/", "trickbot1_1/", "trickbot1_2/", "trickbot1_3/", "trickbot1_5/"])
	print("-------Caching------------------------------")
	CachedLCS().print_stat()
	CachedCustomLCS().print_stat()
	CachedSW().print_stat()
