import string
import warnings
from typing import Iterable, Tuple, Dict, List

import numpy as np
from matplotlib import pyplot as plt
from sklearn.cluster import SpectralClustering, DBSCAN, OPTICS
from sklearn.metrics import silhouette_score

from comparaison_classes import CachedCustomLCS, Singleton
from segmentation import get_segmentation
from segment_new import get_seg, color_dictionary

# TODO: explain
warnings.filterwarnings("ignore", message="Graph is not fully connected, spectral embedding may not work as expected.")

DEBUG = True
GRAPHS = False

actions = ['HANDSHAKE',
           "HANDSHAKE_FAILED",
           'TERM',
           'TERM_RST',
           "INCOMING",
           'INCOMING_TLS',
           'OUTGOING',
           'OUTGOING_TLS',
           'TLS_HANDSHAKE',
           'TLS_HANDSHAKE_FAILED',
           'ACK']


def segmented_to_cpp_compatible(segmented_flows: Iterable) -> Tuple:
	"""
	Convert the segmented flows generated by segment script to a numerical format usable by the C++ script
	:param segmented_flows: python generated list of flows ([['HANDSHAKE', [0, 2], ...])
	:return: segmented flows in C++ format ([((0, 3, ...]) with tuples to allow caching with hashable objects.
	"""
	
	list_of_flows = []
	for flow in segmented_flows:
		new_flow = []
		for sequence in flow:
			new_seq = sequence[:]
			new_seq[0] = actions.index(sequence[0])
			new_seq[1] = new_seq[1][1] - new_seq[1][0] + 1
			new_seq[2] = new_seq[2][1] - new_seq[2][0]
			new_flow.append(tuple(new_seq))
		list_of_flows.append(tuple(new_flow))
	cpp_segmented_flows = tuple(list_of_flows)
	return cpp_segmented_flows


def custom_dist(a, b):
	return a != b


def build_similarity_matrix(input_flows: Iterable) -> np.ndarray:
	"""
	Build the similarity matrix of a list of segmented flows
	:param input_flows: segmented flows
	:return: similarity matrix
	"""
	LCS_engine = CachedCustomLCS(c_lib=False)
	X = np.array(input_flows, dtype=object)
	n = X.shape[0]
	similarities = np.zeros((n, n))
	for i in range(n):
		for j in range(i):
			similarities[i][j] = LCS_engine.compute(X[i], X[j])
	similarity_matrix = (similarities + similarities.T)
	np.fill_diagonal(similarity_matrix, 1)
	return similarity_matrix


def cluster_segmented_flow(segmented_flow, nb_class=None, method="spectral") -> Tuple[List, int]:
	"""
	Cluster a list of segmented flows into nb_class different clusters
	:param segmented_flow: list of segmented flows
	:param nb_class: number of clusters
	:param method: method for clustering ("spectral", "dbscan", "optics")
	:return: list of cluster id for every flows, number of classes
	"""
	stringlify_segmentation = segmented_to_cpp_compatible(segmented_flow)
	sim_matrix = build_similarity_matrix(stringlify_segmentation)
	dist_matrix = sim_matrix.copy()
	dist_matrix = (1 - dist_matrix) * 100
	if nb_class is None:
		nb_class = evaluate_clustering(segmented_flow, sim_matrix, dist_matrix)
		print(f"Nb of classes : {nb_class}")
	if method == "spectral":
		clustering = SpectralClustering(n_clusters=nb_class, affinity="precomputed", assign_labels="discretize",
		                                random_state=42, n_jobs=-1).fit(sim_matrix)
		return clustering.labels_, nb_class
	elif method == "dbscan":
		clustering = DBSCAN(eps=0.9, metric="precomputed", n_jobs=-1).fit(dist_matrix)
		labels_raw = clustering.labels_
		labels_raw[labels_raw == -1] = max(labels_raw)
		return labels_raw, max(labels_raw) + 1
	elif method == "optics":
		clustering = OPTICS(metric="precomputed", n_jobs=-1).fit(dist_matrix)
		labels_raw = clustering.labels_
		labels_raw[labels_raw == -1] = max(labels_raw)
		return labels_raw, max(labels_raw) + 1


def visualize_clustering(cluster_indexes_list: List, segmented_flows_list: List) -> None:
	"""
	Visualize one clustering
	:param cluster_indexes_list: list of cluster ids
	:param segmented_flows_list: list of segmented flows
	:return:
	"""
	assert (len(cluster_indexes_list) == len(segmented_flows_list))
	n_classes = max(cluster_indexes_list) + 1
	plot_max_y_indexes = [0 for _ in range(n_classes)]
	for i in range(len(segmented_flows_list)):
		segmentation = segmented_flows_list[i]
		cluster_index = cluster_indexes_list[i] + 1
		plt.subplot(n_classes + 1, 1, cluster_index)
		for j in range(len(segmentation)):
			color = color_dictionary.get(segmentation[j][0], 'tab:orange')
			plt.broken_barh([(int(segmentation[j][1][0]), 1 + int(segmentation[j][1][1]) - int(segmentation[j][1][0]))],
			                (plot_max_y_indexes[cluster_index - 1], 1), facecolors=color, label=segmentation[j][0])
			plt.xticks([], [])
		plot_max_y_indexes[cluster_index - 1] += 1
	# Display labels
	fig = plt.gcf()
	st = fig.suptitle("Clustering visualization", fontsize="x-large")
	lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]
	ax2 = fig.add_subplot(n_classes + 1, 1, n_classes + 1)
	ax2.axis("off")
	label_dict = {}
	for elem in lines_labels:
		by_label = dict(zip(elem[1], elem[0]))
		label_dict.update(by_label)
	bbox = ax2.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
	ax2.legend(label_dict.values(), label_dict.keys(), loc="center", ncol=3, bbox_to_anchor=(0.5, 0))
	plt.show()


def evaluate_clustering(segmented_flows_list: List, sim=None, dist=None):
	"""
	Function to evaluate one clustering
	:param segmented_flows_list: list of segmented flows
	:param sim: similarity matrix
	:param dist: distance matrix
	:return:
	"""
	if sim is None or dist is None:
		stringlify_segmentation = segmented_to_cpp_compatible(segmented_flows_list)
		sim = build_similarity_matrix(stringlify_segmentation)
		dist = sim.copy()
		dist = 1 - dist
	scores = []
	range_nb_cluster = list(range(2, 15))
	for i in range_nb_cluster:
		try:
			cluster_indexes, _ = cluster_segmented_flow(segmented_flows_list, i, method="spectral")
			scores.append(silhouette_score(dist, cluster_indexes, metric="precomputed"))
		except:  # Dont know why this error happen
			scores.append(0)
	# Agressive clustering
	normal_high = range_nb_cluster[np.argmax(scores)]
	tuple_list = [(range_nb_cluster[i], score) for i, score in enumerate(scores)]
	tuple_list.sort(reverse=True, key=lambda a: a[1])
	agressive_high = max([a[0] for a in tuple_list[:3]])
	print(f"Normal={normal_high}, agressive={agressive_high}")
	return agressive_high


if __name__ == "__main__":
	segmentations, _ = get_seg(path="./benign2/")
	cluster_indexes, nb_class = cluster_segmented_flow(segmentations, None, method="spectral")
	# evaluate_clustering(segmentations)
	visualize_clustering(cluster_indexes, segmentations)
	CachedCustomLCS().print_stat()
