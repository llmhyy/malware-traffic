import string
import warnings
from typing import Iterable, Tuple, Dict, List

import numpy as np
from matplotlib import pyplot as plt
from sklearn.cluster import SpectralClustering, DBSCAN, OPTICS
from sklearn.metrics import silhouette_score

from comparaison_classes import CachedCustomLCS, Singleton
from segmentation import get_segmentation

# TODO: explain
warnings.filterwarnings("ignore", message="Graph is not fully connected, spectral embedding may not work as expected.")

# TODO: documentation

DEBUG = True
GRAPHS = False


class PacketObject:
	"""
	Not used anymore because lists/standard python+numpy needs to be used for C implementation of Custom LCS
	Hash function to ensure it can be a dictionary key
	"""
	
	def __init__(self, seq_type, **kwargs):
		self.type = seq_type
		self.size = kwargs.get('size', None)
		self.tls_version = kwargs.get('tls_version', None)
	
	def __eq__(self, other):
		if not isinstance(other, PacketObject):
			return False
		return self.type == other.type and self.size == other.size and self.tls_version == other.tls_version
	
	def __hash__(self):
		return hash((self.type, self.size, self.tls_version))


class SegmentedConvertor(metaclass=Singleton):
	# Used to convert the segmented flows to numerical representation to allow computation of LCS
	# Single class instanciation to maintain a coherent type conversion (HANDSHAKE, etc)
	
	def __init__(self):
		self.type_to_int_dict = {}
	
	def segmented_to_typegroups(self, segmented_list: Iterable) -> Tuple:
		list_of_packetobjects = []
		if not self.type_to_int_dict:
			current_int = 0
		else:
			current_int = self.type_to_int_dict[max(self.type_to_int_dict, key=self.type_to_int_dict.get)] + 1
		for flow in segmented_list:
			flow_obj = []
			for sequence in flow:
				seq_type = sequence[0]
				if seq_type in self.type_to_int_dict:
					seq_type_int = self.type_to_int_dict[seq_type]
				else:
					seq_type_int = current_int
					self.type_to_int_dict[seq_type] = current_int
					current_int += 1
				pck_len = sequence[1][1] - sequence[1][0] + 1
				# time_len = sequence[2][1] - sequence[2][0]
				# IF type tls handshake : add tls metadata
				typegroup = [seq_type_int]
				if seq_type in ["TLS_HANDSHAKE", 'Failed_TLS_handshake']:
					typegroup.append(int(sequence[3]))
					typegroup.append(-2)
				elif seq_type in ["IN_TLS", "OUT_TLS"]:
					typegroup.append(int(sequence[4]))
					typegroup.append(int(sequence[3]))
				elif seq_type in ["IN", "OUT"]:
					typegroup.append(-2)
					typegroup.append(int(sequence[3]))
				else:
					typegroup.append(-2)
					typegroup.append(-2)
				flow_obj += tuple([tuple(typegroup) for _ in range(pck_len)])
			list_of_packetobjects.append(tuple(flow_obj))
		return tuple(list_of_packetobjects)
	
	def print_dict(self) -> Dict:
		return self.type_to_int_dict


def segmented_to_char(segmented_list: Iterable) -> Tuple[List, Dict]:
	type_to_char_dict = {}
	current_letter = iter(string.ascii_lowercase)
	list_of_str = []
	for flow in segmented_list:
		str_from_seq = ""
		for sequence in flow:
			seq_type = sequence[0]
			pck_len = sequence[1][1] - sequence[1][0] + 1
			if seq_type in type_to_char_dict:
				str_from_seq += type_to_char_dict[seq_type] * pck_len
			else:
				letter = next(current_letter)
				type_to_char_dict[seq_type] = letter
				str_from_seq += letter * pck_len
		
		list_of_str.append(str_from_seq)
	
	return list_of_str, type_to_char_dict


def custom_dist(a, b):
	return a != b


def build_similarity_matrix(input_flows: Iterable) -> np.ndarray:
	LCS_engine = CachedCustomLCS()
	X = np.array(input_flows, dtype=object)
	n = X.shape[0]
	similarities = np.zeros((n, n))
	for i in range(n):
		for j in range(i):
			similarities[i][j] = LCS_engine.compute(X[i], X[j])
	similarity_matrix = (similarities + similarities.T)
	np.fill_diagonal(similarity_matrix, 1)
	return similarity_matrix


def cluster_segmented_flow(segmented_flow, nb_class=None, method="spectral"):
	segmented_convertor = SegmentedConvertor()
	stringlify_segmentation = segmented_convertor.segmented_to_typegroups(segmented_flow)
	sim_matrix = build_similarity_matrix(stringlify_segmentation)
	dist_matrix = sim_matrix.copy()
	dist_matrix = (1 - dist_matrix) * 100
	if nb_class is None:
		nb_class = evaluate_clustering(segmented_flow, sim_matrix, dist_matrix)
		print(f"Nb of classes : {nb_class}")
	if method == "spectral":
		clustering = SpectralClustering(n_clusters=nb_class, affinity="precomputed", assign_labels="discretize",
		                                random_state=42, n_jobs=-1).fit(sim_matrix)
		return clustering.labels_, nb_class
	elif method == "dbscan":
		clustering = DBSCAN(eps=0.9, metric="precomputed", n_jobs=-1).fit(dist_matrix)
		labels_raw = clustering.labels_
		labels_raw[labels_raw == -1] = max(labels_raw)
		return labels_raw, max(labels_raw) + 1
	elif method == "optics":
		clustering = OPTICS(metric="precomputed", n_jobs=-1).fit(dist_matrix)
		labels_raw = clustering.labels_
		labels_raw[labels_raw == -1] = max(labels_raw)
		return labels_raw, max(labels_raw) + 1


def visualize_clustering(cluster_indexes, segmentations):
	# TODO: import it
	color_dictionary = {
		'HANDSHAKE': 'xkcd:goldenrod',
		'TERM': 'xkcd:maroon',
		"IN": 'xkcd:green',
		'IN_TLS': 'xkcd:chartreuse',
		'OUT': 'xkcd:blue',
		'OUT_TLS': 'xkcd:sky blue',
		'TERM_RST': 'xkcd:red',
		"HANDSHAKE_FAILED": 'xkcd:purple',
		'TLS_handshake': 'tab:brown',
		'Failed_TLS_handshake': 'xkcd:crimson'
	}
	assert (len(cluster_indexes) == len(segmentations))
	n_classes = max(cluster_indexes) + 1
	plot_max_y_indexes = [0 for _ in range(n_classes)]
	for i in range(len(segmentations)):
		segmentation = segmentations[i]
		cluster_index = cluster_indexes[i] + 1
		plt.subplot(n_classes + 1, 1, cluster_index)
		for j in range(len(segmentation)):
			color = color_dictionary.get(segmentation[j][0], 'tab:orange')
			plt.broken_barh([(int(segmentation[j][1][0]), 1 + int(segmentation[j][1][1]) - int(segmentation[j][1][0]))],
			                (plot_max_y_indexes[cluster_index - 1], 1), facecolors=color, label=segmentation[j][0])
			plt.xticks([], [])
		plot_max_y_indexes[cluster_index - 1] += 1
	# Display labels
	fig = plt.gcf()
	st = fig.suptitle("Clustering visualization", fontsize="x-large")
	lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]
	ax2 = fig.add_subplot(n_classes + 1, 1, n_classes + 1)
	ax2.axis("off")
	label_dict = {}
	for elem in lines_labels:
		by_label = dict(zip(elem[1], elem[0]))
		label_dict.update(by_label)
	bbox = ax2.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
	ax2.legend(label_dict.values(), label_dict.keys(), loc="center", ncol=3, bbox_to_anchor=(0.5, 0))
	plt.show()


def evaluate_clustering(segmentations, sim=None, dist=None):
	if sim is None or dist is None:
		segmented_convertor = SegmentedConvertor()
		stringlify_segmentation = segmented_convertor.segmented_to_typegroups(segmentations)
		sim = build_similarity_matrix(stringlify_segmentation)
		dist = sim.copy()
		dist = 1 - dist
	scores = []
	range_nb_cluster = range(2, 15)
	for i in range_nb_cluster:
		try:
			cluster_indexes, _ = cluster_segmented_flow(segmentations, i, method="spectral")
			scores.append(silhouette_score(dist, cluster_indexes, metric="precomputed"))
		except:  # Dont know why this error happen
			scores.append(0)
	return list(range_nb_cluster)[np.argmax(scores)]


if __name__ == "__main__":
	segmentations, _ = get_segmentation(path="./trickbot1_2/")
	cluster_indexes, nb_class = cluster_segmented_flow(segmentations, 6, method="spectral")
	evaluate_clustering(segmentations)
	# CachedCustomLCS().print_stat()
	visualize_clustering(cluster_indexes, segmentations)
