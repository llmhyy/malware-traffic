import string
import warnings
from typing import Iterable, Tuple, Dict, List

import numpy as np
from matplotlib import pyplot as plt
from sklearn.cluster import SpectralClustering, DBSCAN, OPTICS
from sklearn.metrics import silhouette_score

from comparaison_classes import CachedCustomLCS, Singleton
from segmentation import get_segmentation
from segment_new import get_seg, color_dictionary

# TODO: documentation
# TODO: explain
warnings.filterwarnings("ignore", message="Graph is not fully connected, spectral embedding may not work as expected.")

DEBUG = True
GRAPHS = False

actions = ['HANDSHAKE',
           "HANDSHAKE_FAILED",
           'TERM',
           'TERM_RST',
           "INCOMING",
           'INCOMING_TLS',
           'OUTGOING',
           'OUTGOING_TLS',
           'TLS_HANDSHAKE',
           'TLS_HANDSHAKE_FAILED',
           'ACK']


def segmented_to_cpp_compatible(segmented_flows: Iterable) -> Tuple:
	list_of_flows = []
	for flow in segmented_flows:
		new_flow = []
		for sequence in flow:
			new_seq = sequence[:]
			new_seq[0] = actions.index(sequence[0])
			new_seq[1] = new_seq[1][1] - new_seq[1][0] + 1
			new_seq[2] = new_seq[2][1] - new_seq[2][0]
			# FIXME: Warning !!! nb of packets not used
			# new_flow += tuple([tuple(typegroup) for _ in range(pck_len)])
			new_flow.append(tuple(new_seq))
		list_of_flows.append(tuple(new_flow))
	a = tuple(list_of_flows)
	return a


def custom_dist(a, b):
	return a != b


def build_similarity_matrix(input_flows: Iterable) -> np.ndarray:
	LCS_engine = CachedCustomLCS(c_lib=False)
	X = np.array(input_flows, dtype=object)
	n = X.shape[0]
	similarities = np.zeros((n, n))
	for i in range(n):
		for j in range(i):
			similarities[i][j] = LCS_engine.compute(X[i], X[j])
	similarity_matrix = (similarities + similarities.T)
	np.fill_diagonal(similarity_matrix, 1)
	return similarity_matrix


def cluster_segmented_flow(segmented_flow, nb_class=None, method="spectral"):
	stringlify_segmentation = segmented_to_cpp_compatible(segmented_flow)
	sim_matrix = build_similarity_matrix(stringlify_segmentation)
	dist_matrix = sim_matrix.copy()
	dist_matrix = (1 - dist_matrix) * 100
	if nb_class is None:
		nb_class = evaluate_clustering(segmented_flow, sim_matrix, dist_matrix)
		print(f"Nb of classes : {nb_class}")
	if method == "spectral":
		clustering = SpectralClustering(n_clusters=nb_class, affinity="precomputed", assign_labels="discretize",
		                                random_state=42, n_jobs=-1).fit(sim_matrix)
		return clustering.labels_, nb_class
	elif method == "dbscan":
		clustering = DBSCAN(eps=0.9, metric="precomputed", n_jobs=-1).fit(dist_matrix)
		labels_raw = clustering.labels_
		labels_raw[labels_raw == -1] = max(labels_raw)
		return labels_raw, max(labels_raw) + 1
	elif method == "optics":
		clustering = OPTICS(metric="precomputed", n_jobs=-1).fit(dist_matrix)
		labels_raw = clustering.labels_
		labels_raw[labels_raw == -1] = max(labels_raw)
		return labels_raw, max(labels_raw) + 1


def visualize_clustering(cluster_indexes, segmentations):
	assert (len(cluster_indexes) == len(segmentations))
	n_classes = max(cluster_indexes) + 1
	plot_max_y_indexes = [0 for _ in range(n_classes)]
	for i in range(len(segmentations)):
		segmentation = segmentations[i]
		cluster_index = cluster_indexes[i] + 1
		plt.subplot(n_classes + 1, 1, cluster_index)
		for j in range(len(segmentation)):
			color = color_dictionary.get(segmentation[j][0], 'tab:orange')
			plt.broken_barh([(int(segmentation[j][1][0]), 1 + int(segmentation[j][1][1]) - int(segmentation[j][1][0]))],
			                (plot_max_y_indexes[cluster_index - 1], 1), facecolors=color, label=segmentation[j][0])
			plt.xticks([], [])
		plot_max_y_indexes[cluster_index - 1] += 1
	# Display labels
	fig = plt.gcf()
	st = fig.suptitle("Clustering visualization", fontsize="x-large")
	lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]
	ax2 = fig.add_subplot(n_classes + 1, 1, n_classes + 1)
	ax2.axis("off")
	label_dict = {}
	for elem in lines_labels:
		by_label = dict(zip(elem[1], elem[0]))
		label_dict.update(by_label)
	bbox = ax2.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
	ax2.legend(label_dict.values(), label_dict.keys(), loc="center", ncol=3, bbox_to_anchor=(0.5, 0))
	plt.show()


def evaluate_clustering(segmentations, sim=None, dist=None):
	if sim is None or dist is None:
		stringlify_segmentation = segmented_to_cpp_compatible(segmentations)
		sim = build_similarity_matrix(stringlify_segmentation)
		dist = sim.copy()
		dist = 1 - dist
	scores = []
	range_nb_cluster = range(2, 15)
	for i in range_nb_cluster:
		try:
			cluster_indexes, _ = cluster_segmented_flow(segmentations, i, method="spectral")
			scores.append(silhouette_score(dist, cluster_indexes, metric="precomputed"))
		except:  # Dont know why this error happen
			scores.append(0)
	return list(range_nb_cluster)[np.argmax(scores)]


if __name__ == "__main__":
	segmentations, _ = get_seg(path="./trickbot1_5/")
	cluster_indexes, nb_class = cluster_segmented_flow(segmentations, None, method="spectral")
	# evaluate_clustering(segmentations)
	visualize_clustering(cluster_indexes, segmentations)
	CachedCustomLCS().print_stat()
