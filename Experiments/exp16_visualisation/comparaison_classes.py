from typing import Tuple

import matplotlib.pyplot as plt
import numpy as np
from entropy import BlackListProvider

import pylcs  # I rewrote this library /!\


def avg(x, y):
	return (x + y) / 2


class Singleton(type):
	"""
	Singleton design pattern to allow the comparaison functions to be globaly cached
	"""
	_instances = {}
	
	def __call__(cls, *args, **kwargs):
		if cls not in cls._instances:
			cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
		return cls._instances[cls]


class Api2Listofint(metaclass=Singleton):
	def __init__(self):
		self.seq2int = {}
		self.current = 1
	
	def convert(self, x):
		list_return = []
		for item in x:
			character = self.seq2int.get(item)
			if character is None:
				character = self.current
				self.seq2int[item] = self.current
				self.current += 1
			list_return.append(character)
		return list_return


class CachedCustomLCS(metaclass=Singleton):
	"""
	Class allowing to compute the custom LCS between flows
	"""
	
	def __init__(self, c_lib=True):
		"""
		The cache dict allows an unlimited caching (can be a problem, then need to implement LRU dictionary)
		Other variales are for statistics usage.
		:param c_lib: whether to use or not the C binding from the pylcs lybrary
		"""
		self.cache = {}
		self.operations = 0
		self.misses = 0
		if c_lib:
			self.c_lib = True
		else:
			self.c_lib = False
	
	def compute(self, x: Tuple, y: Tuple) -> float:
		"""
		Compute the similarity between two sequences x and y.
		For the caching, oth x and y are dictionary keys, so there is a need to convert them into a tupple to make them hashable and immutable.
		:param x: seq 1
		:param y: seq 2
		:return: similarity score
		"""
		self.operations += 1
		x, y = tuple(x), tuple(y)
		if len(x) == 0 or len(y) == 0:
			return 0
		result = self.cache.get(frozenset([x, y]))
		
		if not result:
			self.misses += 1
			old_x, old_y = x, y
			x, y = np.array(x), np.array(y)
			if self.c_lib:
				# Return a result divided by max len
				result = pylcs.custom_lcs(x, y)
			else:
				result = self.custom_lcs(x, y)
			self.cache[frozenset([old_x, old_y])] = result
		return result
	
	@staticmethod
	def custom_lcs(x: np.ndarray, y: np.ndarray) -> float:
		dp_table = np.zeros((len(x) + 1, len(y) + 1))
		for i in range(1, len(x) + 1):
			for j in range(1, len(y) + 1):
				if x[i - 1][0] == y[j - 1][0]:  # Types
					# Score
					list_scores = [1]
					# Fetch tls and size
					size1, size2 = x[i - 1][2], y[j - 1][2]
					tls1, tls2 = x[i - 1][1], y[j - 1][1]
					is_size = size1 != -2 and size2 != -2
					is_tls = tls1 != -2 and tls2 != -2
					if is_size and size1 != 0 and size2 != 0:
						size1, size2 = max(size1, size2), min(size1, size2)
						list_scores.append(1 - ((size1 - size2) / size1))
					elif is_size and ((size1 == 0) != (size2 == 0)):
						list_scores.append(1)
					if is_tls:
						list_scores.append(0.5 + 0.5 * (tls1 == tls2))
					final_score = np.sum(list_scores) / len(list_scores)
					dp_table[i, j] = final_score + dp_table[i - 1, j - 1]
				else:
					dp_table[i, j] = max(dp_table[i, j - 1], dp_table[i - 1, j])
		return dp_table[len(x), len(y)] / max(len(x), len(y))
	
	def print_stat(self) -> None:
		if self.operations:
			print(f"Custom LCS --- {self.operations} ops, {(self.misses / self.operations):.2f} missrate")


class CachedLCS(metaclass=Singleton):
	"""
	Class allowing to compute the LCS score between API call sequences
	"""
	
	def __init__(self, c_lib=True):
		"""
		The cache dict allows an unlimited caching (can be a problem, then need to implement LRU dictionary)
		Other variales are for statistics usage.
		:param c_lib: whether to use or not the C binding from the pylcs lybrary
		"""
		self.cache = {}
		self.operations = 0
		self.misses = 0
		self.blacklist_filter = np.array(BlackListProvider().get_blacklist())
		self.blacklist_filter = np.array([])
		
		if c_lib:
			self.seq2txt = {}
			self.current = 1
			self.c_lib = True
		else:
			self.c_lib = False
	
	def compute(self, x, y):
		"""
		Compute the similarity between two sequences x and y.
		For the caching, oth x and y are dictionary keys, so there is a need to convert them into a tupple to make them hashable and immutable.
		:param x: seq 1
		:param y: seq 2
		:return: similarity score
		"""
		self.operations += 1
		if self.blacklist_filter.shape[0] != 0:
			print("before diff : ", len(x), len(y))
			x, y = np.setdiff1d(x, self.blacklist_filter), np.setdiff1d(y, self.blacklist_filter)
			print("after diff : ", len(x), len(y))
		x, y = tuple(x), tuple(y)
		if len(x) == 0 or len(y) == 0:
			return 0
		result = self.cache.get(frozenset([x, y]))
		
		# Transform the numpy ndarray list into tuple to make it hashable
		# Keys from dict need to be hashable
		# The frozenset is hashable
		if not result:
			self.misses += 1
			if self.c_lib:
				old_x, old_y = x, y
				x = self.transform2text(x)
				y = self.transform2text(y)
				result = pylcs.lcs(x, y)
				result /= max(len(x), len(y))
				result = min(result, 1)
				self.cache[frozenset([old_x, old_y])] = result
			else:
				result = self.lcs_dp(x, y)
				self.cache[frozenset([x, y])] = result
		return result
	
	def transform2text(self, x):
		str_return = ""
		for item in x:
			character = self.seq2txt.get(item)
			if character is None:
				character = chr(self.current)
				self.seq2txt[item] = chr(self.current)
				self.current += 1
			str_return += character
		return str_return
	
	def get_seq2text_map(self):
		return self.seq2txt
	
	def get_nb_text(self):
		return self.current
	
	@staticmethod
	def lcs_dp(x, y):
		dp_table = np.zeros((len(x) + 1, len(y) + 1))
		for i in range(1, len(x) + 1):
			for j in range(1, len(y) + 1):
				if x[i - 1] == y[j - 1]:
					dp_table[i - 1, j - 1] = 1 + dp_table[i - 2, j - 2]
				else:
					dp_table[i - 1, j - 1] = max(dp_table[i - 1, j - 2], dp_table[i - 2, j - 1])
		return dp_table[len(x) - 1, len(y) - 1] / min(len(x), len(y))
	
	def print_stat(self):
		if self.operations:
			print(f"LCS --- {self.operations} ops, {(self.misses / self.operations):.2f} missrate")


class CachedDTW(metaclass=Singleton):
	def __init__(self):
		self.cache = {}
		self.operations = 0
		self.misses = 0
		self.scores = []
	
	def compute(self, x, y):
		result = self.cache.get(frozenset([x, y]))
		self.operations += 1
		if not result:
			self.misses += 1
			result = self.distance(x, y)
			self.cache[frozenset([x, y])] = result
		self.scores.append(result)
		return result
	
	def show_score_histo(self):
		plt.figure()
		plt.hist(self.scores, bins=20)
		plt.title("Histogram of DTW scores")
		plt.show()
	
	@staticmethod
	def custom_dist(a, b):
		return a != b
	
	@staticmethod
	def distance(a, b):
		l1, l2 = len(a), len(b)
		a = [ord(i) for i in a]
		b = [ord(i) for i in b]
		
		dtw_distance, _ = fastdtw(list(a), list(b), dist=CachedDTW.custom_dist)
		sim = (max(l1, l2) - dtw_distance) / max(l1, l2)
		return sim
	
	def print_stat(self):
		if self.operations:
			print(f"DTW --- {self.operations} ops, {(self.misses / self.operations):.2f} missrate")


class CachedSW(metaclass=Singleton):
	def __init__(self, c_lib=True):
		self.cache = {}
		self.operations = 0
		self.misses = 0
		self.blacklist_filter = np.array(BlackListProvider().get_blacklist())
		self.blacklist_filter = np.array([])
		if c_lib:
			self.seq2txt = {}
			self.current = 1
			self.c_lib = True
		else:
			self.c_lib = False
	
	def compute(self, x, y):
		self.operations += 1
		if self.blacklist_filter.shape[0] != 0:
			x, y = np.setdiff1d(x, self.blacklist_filter), np.setdiff1d(y, self.blacklist_filter)
		x, y = tuple(x), tuple(y)
		if len(x) == 0 or len(y) == 0:
			return 0
		result = self.cache.get(frozenset([x, y]))
		
		# Transform the numpy ndarray list into tuple to make it hashable
		# Keys from dict need to be hashable
		# The frozenset is hashable
		if not result:
			self.misses += 1
			if self.c_lib:
				old_x, old_y = x, y
				x = self.transform2text(x)
				y = self.transform2text(y)
				result = pylcs.smith_w(x, y, 1, 2)
				result /= max(len(x), len(y))
				result = min(result, 1)
				self.cache[frozenset([old_x, old_y])] = result
			else:
				result = self.sw(x, y, 1, 1) / min(len(x), len(y))
				self.cache[frozenset([x, y])] = result
		return result
	
	def transform2text(self, x):
		str_return = ""
		for item in x:
			character = self.seq2txt.get(item)
			if character is None:
				character = chr(self.current)
				self.seq2txt[item] = chr(self.current)
				self.current += 1
			str_return += character
		return str_return
	
	@staticmethod
	def sw(x1, x2, s=1, w=1):
		n1 = len(x1)
		n2 = len(x2)
		
		S = np.zeros((n1, n2))
		
		for i in range(n1):
			for j in range(n2):
				if x1[i] == x2[j]:
					S[i, j] = s
				else:
					S[i, j] = -s
		
		H = np.zeros((n1 + 1, n2 + 1))
		max2 = np.zeros(n1 + 1)
		
		for j in range(1, n2 + 1):
			for t in range(n1 + 1):
				max2[t] = max(max2[t], H[t, j - 1]) - w
			max1 = 0
			for i in range(1, n1 + 1):
				max1 = max(H[i - 1, j], max1) - w
				H[i, j] = max(max(H[i - 1, j - 1] + S[i - 1, j - 1], max1), max2[i], 0)
		return np.max(H)
	
	def print_stat(self):
		if self.operations:
			print(f"SW --- {self.operations} ops, {(self.misses / self.operations):.2f} missrate")


if __name__ == '__main__':
	c = CachedLCS().compute("aacaabaa", "aaaaabdd")
	d = CachedSW().compute("aacaabaa", "aaaaabdd")
	print(c, d)
